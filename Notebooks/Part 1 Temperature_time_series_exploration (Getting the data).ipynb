{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part One:  Exploration of Canadian Temperature \n",
    "## Getting the Canadian Temperature Data\n",
    "\n",
    "This is the first part in the series of analysing temperature in Canadian series. This notebook focus only on getting the time series. It can be considered as a basic intro but several aspects are covered. This notebook only focus on one city as well. The principle derived here applies to most of the other cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature Time Series Visualization\n",
    "\n",
    "$\\mathbf{Time\\ series}$ generally refers to data collected over time intervals. Its dependence on time breaks the independence variable assumption used in regression analysis.\n",
    "This tutorial aims to show some necessary and essential steps taken before performing  a time series of $\\textit{visualization and forcasting}$. Exploration deals with idensify features and visualization of the time series, while forecasting refers to making predictions for future trends. It could be in the market, stock price, accidents, the number of patients arriving at a clinic. Most of the concepts presented here equally apply to most time series data. \n",
    "\n",
    "In this set of not books on exploration notebooks, however, we will be working exclusively with temperature data. The data is from the NOAA weather station, and we will pick one station in Prince Albert, a city in SK, Canada. The data, as well as its properties, can be found in the [NOAA website](https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ \"NOAA website\"). There are three other stations in Canada, but we will focus on this one which is part of the GCOS Surface Network (GSN). In the next project, we will work with multiple cities.\n",
    "\n",
    "## 1. Overview of notebooks to follow\n",
    "First, note that this notebook follows a similar approach to that in ref [here](https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/?utm_source=blog&utm_medium=stockmarketpredictionarticle).It is also an introductory article on straightforward concepts about time series which will cover aspects like\n",
    "\n",
    "   - Learn the steps to create a Time Series dataset from the NOAA data\n",
    "   - Display some features of raw data\n",
    "   - Prepare or clean the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "#used to get data directly from the URL\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the size of the default parameter sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting the data\n",
    "The data as menntion is downloaded from [NOAA link here](ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt).\n",
    " - Loading and Handling Time Series in Pandas\n",
    " - How to Check Stationarity of a Time Series?\n",
    " - How to make a Time Series Stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('stations.txt', <email.message.Message at 0x7f6450034940>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the data of the stations are stored in stations\n",
    "urllib.request.urlretrieve('ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt','stations.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the available list of stations that stores the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACW00011604  17.1167  -61.7833   10.1    ST JOHNS COOLIDGE FLD                       \\n',\n",
       " 'ACW00011647  17.1333  -61.7833   19.2    ST JOHNS                                    \\n',\n",
       " 'AE000041196  25.3330   55.5170   34.0    SHARJAH INTER. AIRP            GSN     41196\\n',\n",
       " 'AEM00041194  25.2550   55.3640   10.4    DUBAI INTL                             41194\\n',\n",
       " 'AEM00041217  24.4330   54.6510   26.8    ABU DHABI INTL                         41217\\n',\n",
       " 'AEM00041218  24.2620   55.6090  264.9    AL AIN INTL                            41218\\n',\n",
       " 'AF000040930  35.3170   69.0170 3366.0    NORTH-SALANG                   GSN     40930\\n',\n",
       " 'AFM00040938  34.2100   62.2280  977.2    HERAT                                  40938\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('stations.txt','r').readlines()[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look for Canadian stations with GSN. The code name of stations in Canada starts with 'CA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Canada_stations = {}\n",
    "for line in open('stations.txt','r'):\n",
    "    if (line[:2] == 'CA') and ('GSN' in line):\n",
    "        fields = line.split()\n",
    "        \n",
    "        Canada_stations[fields[0]] = ' '.join(fields[4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check a few stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findstation(s):\n",
    "    found = {code: name for code,name in Canada_stations.items() if s in name}\n",
    "    print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CA004056240': 'SK PRINCE ALBERT A GSN 71869'}\n"
     ]
    }
   ],
   "source": [
    "findstation('PRINCE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with Prince Albert data set. There is nothing special about Prince Albert. One can pick any city. The station ID is CA004056240. It is used below to get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CA004056240.dly', <http.client.HTTPMessage at 0x7f6450065588>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve('https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/gsn/CA004056240.dly', 'CA004056240.dly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CA004056240194212TMAX -150  C -100  C  -83  C  -94  C -139  C -161  C -194  C -211  C -178  C -217  C -206  C  -72  C   -6  C  -94  C  -61  C  -94  C -189  C -283  C -194  C -161  C -139  C -150  C -156  C -128  C -156  C -183  C  -61  C  -94  C -261  C -206  C -256  C\\n',\n",
       " 'CA004056240194212TMIN -233  C -222  C -200  C -167  C -194  C -206  C -339  C -306  C -278  C -306  C -328  C -311  C -167  C -117  C -189  C -161  C -217  C -350  C -356  C -239  C -183  C -256  C -233  C -317  C -311  C -306  C -300  C -244  C -328  C -317  C -333  C\\n',\n",
       " 'CA004056240194212PRCP    0T C   18  C   23  C   10  C    0T C    0T C    0T C    0  C   13  C    0  C    0  C    8  C    3  C    8  C    8  C   58  C    3  C    0  C    5  C    5  C    3  C   69  C   10  C    0  C    0  C    0  C   18  C    0T C    3  C    8  C    5  C\\n',\n",
       " 'CA004056240194212SNOW    0T C   18  C   23  C   10  C    0T C    0T C    0T C    0  C   13  C    0  C    0  C    8  C    3  C    8  C    8  C   58  C    3  C    0  C    5  C    5  C    3  C   69  C   10  C    0  C    0  C    0  C   18  C    0T C    3  C    8  C    5  C\\n',\n",
       " 'CA004056240194301TMAX -217  C -256  C -217  C -128  C -206  C  -94  C   22  C   44  C   39  C    6  C -156  C   11  C   44  C  -17  C -150  C -289  C -250  C -250  C -350  C -350  C -322  C -300  C -322  C -272  C -222  C -211  C -200  C -189  C -172  C -172  C -206  C\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('CA004056240.dly','r').readlines()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data doesn't make so much sense at a first glance. To make sense of the data, there is a [readme.txt](https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt) on the website. Basically, ${-999}$ are NANs. We Below we read a description of a segment of the readme.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['------------------------------\\n',\n",
       " 'Variable   Columns   Type\\n',\n",
       " '------------------------------\\n',\n",
       " 'ID            1-11   Character\\n',\n",
       " 'YEAR         12-15   Integer\\n',\n",
       " 'MONTH        16-17   Integer\\n',\n",
       " 'ELEMENT      18-21   Character\\n',\n",
       " 'VALUE1       22-26   Integer\\n',\n",
       " 'MFLAG1       27-27   Character\\n',\n",
       " 'QFLAG1       28-28   Character\\n',\n",
       " 'SFLAG1       29-29   Character\\n',\n",
       " 'VALUE2       30-34   Integer\\n',\n",
       " 'MFLAG2       35-35   Character\\n',\n",
       " 'QFLAG2       36-36   Character\\n',\n",
       " 'SFLAG2       37-37   Character\\n',\n",
       " '  .           .          .\\n',\n",
       " '  .           .          .\\n',\n",
       " '  .           .          .\\n',\n",
       " 'VALUE31    262-266   Integer\\n',\n",
       " 'MFLAG31    267-267   Character\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve('https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt', 'readme.txt')\n",
    "open('readme.txt','r').readlines()[108:128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning/Formatting the data\n",
    "We definitely need a parser the data. We can note from the data that, each record for example $\\textit{open('CA004056240.dly','r').readlines()[0] }$ is a string. The first entry is a combination of the station name and year, month, and the type of measurement (TMIN, TMAX etc). Below is a parser to convert the data into a record array of multiple types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\text{parsefile}$ helps us read each record from the the station. The parameters specify how the record is read. Let's go through each parameter at a time.\n",
    "\n",
    "$\\textbf{dly_delimiter}$: A quick check [online](https://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html) provides the info that is is where the read breaks. Lets take a look at the first record which is _'CA004056240194212TMAX -150  C -100  C  -83  C  -94  C -139  C -161  C -194  C -211  C -178  C -217  C -206  C  -72  C   -6  C  -94  C  -61  C  -94  C -189  C -283  C -194  C -161  C -139  C -150  C -156  C -128  C -156  C -183  C  -61  C  -94  C -261  C -206  C -256  C\\n'_ First 11 chars, values specifies the station code, next 4 the year, next 2 the month, next 4 the measurement type, then the other values are temperatures and it units C for the next 31 days. After the measurement type, 5 chars (including the space) contains the temperature, and the other 3 (space, C, space) are also read. This is repeated 31 times.\n",
    "\n",
    "$\\textbf{dly_usecols}$: Specify the columns which are used in defining the data. The station code and each of the (_c_) are not used.\n",
    "\n",
    "$\\textbf{dly_dtype}$: The datatypes of each of the columns. We see that the first two the year and month are int while the measurement type is str\n",
    "\n",
    "$\\textbf{dly_names}$: These are names that are used to access each of the columns. The values are specified below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsefile(filename):\n",
    "    '''\n",
    "    Takes a file and parse it to return a numpy array\n",
    "    '''\n",
    "    return np.genfromtxt(filename,\n",
    "                         delimiter = dly_delimiter,\n",
    "                         usecols = dly_usecols,\n",
    "                         dtype = dly_dtype,\n",
    "                         names = dly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dly_delimiter = [11,4,2,4] + [5,1,1,1] * 31 \n",
    "dly_usecols = [1,2,3] + [4*i for i in range(1,32)]\n",
    "dly_dtype = [np.int32,np.int32,(np.str_,4)] + [np.int32] * 31\n",
    "dly_names = ['year','month','obs'] + [str(day) for day in range(1,31+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse Prince Albert's temperature data and check these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1942, 12, 'TMAX', -150, -100, -83, -94, -139, -161, -194, -211, -178, -217, -206, -72, -6, -94, -61, -94, -189, -283, -194, -161, -139, -150, -156, -128, -156, -183, -61, -94, -261, -206, -256)\n",
      "------------------------------Year, month---------------------------------------------------------\n",
      "Year:  1942 Month:  12\n"
     ]
    }
   ],
   "source": [
    "Prince_Albert = parsefile('CA004056240.dly')\n",
    "print(Prince_Albert[0])\n",
    "print('------------------------------Year, month---------------------------------------------------------')\n",
    "print('Year: ', Prince_Albert[0]['year'], 'Month: ',Prince_Albert[0]['month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PRCP', 'SNOW', 'SNWD', 'TAVG', 'TMAX', 'TMIN'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements = set(Prince_Albert['obs']) #Check unique values\n",
    "measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple observation are present, namely 'PRCP', 'SNOW', 'SNWD', 'TAVG', 'TMAX' and 'TMIN'. For now, lets focus on the maximum and minimum temperatures. The data is not in the desired format, so lets rearrange it including the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll(record):\n",
    "    '''\n",
    "    Takes a station temperature data, arrange it as an array of pairs of daily temperature and value\n",
    "    record: input temperature data\n",
    "    Pameters:\n",
    "    -----------\n",
    "    startdate: the date (yr, m) to start considering\n",
    "    dates: Hold a date in daily steps\n",
    "    '''\n",
    "    startdate = np.datetime64('{}-{:02}'.format(record['year'],record['month']))\n",
    "    dates = np.arange(startdate, startdate + np.timedelta64(1,'M'), np.timedelta64(1,'D')) #Daily step increment\n",
    "    \n",
    "    rows = [(date, record[str(i+1)]/10) for i, date in enumerate(dates)]\n",
    "    \n",
    "    return np.array(rows, dtype=[('date','M8[D]'), ('value','d')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is then grouped by day and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getobs(filename, obs):\n",
    "    '''\n",
    "    Parse a record and each line contain montly record that are unrolled and concated to the data variable\n",
    "    Parameters:\n",
    "    ---------------\n",
    "    filename: specific  record\n",
    "    obs: is the observation of choice eh TMAX, TMIN etc\n",
    "\n",
    "    '''\n",
    "    data = np.concatenate([unroll(row) for row in parsefile(filename) if row[2] == obs])\n",
    "    \n",
    "    data['value'][data['value'] == -999.9] = np.nan\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prince_Albert_tmax = getobs('CA004056240.dly','TMAX')\n",
    "Prince_Albert_tmin = getobs('CA004056240.dly','TMIN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some null values. We will replace them by avarage of the two neigbouring values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, nan)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Prince_Albert_tmax['value']), np.mean(Prince_Albert_tmin['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries:  28002\n",
      "Missing values: 1199 \n"
     ]
    }
   ],
   "source": [
    "Prince_Albert_tmax[np.isnan(Prince_Albert_tmax['value'])].size\n",
    "print('Number of entries: ', len(Prince_Albert_tmax)) # Sizetime series\n",
    "print('Missing values: {} '.format(Prince_Albert_tmax[np.isnan(Prince_Albert_tmax['value'])].size)) # Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data shows that the missing values are around the same period but not the same. This notebook is meant to demonstrate basic concepts in time series; we will only use the one of the time series. There are many efficient ways to fill the nans, but for not we will fill them with an interpolation. Since the temperatures are seasonal, before training a model, we can instead fill with average temperatures from other years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillnans(data):\n",
    "    '''\n",
    "    Basically, the nans are filled by the average of the neighbouring two values\n",
    "    '''\n",
    "    dates_float = data['date'].astype(np.float64)    \n",
    "    nan = np.isnan(data['value'])    \n",
    "    data['value'][nan] = np.interp(dates_float[nan], dates_float[~nan], data['value'][~nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillnans(Prince_Albert_tmax)\n",
    "fillnans(Prince_Albert_tmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28002,), (28002,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Prince_Albert_tmax.shape, Prince_Albert_tmax.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.1800103564031135, -5.482544103992572)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Prince_Albert_tmax['value']), np.mean(Prince_Albert_tmin['value'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
